# ai_ethics_chat/backend/app.py

import os
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ê°™ì€ ë””ë ‰í„°ë¦¬(backend)ì— ìˆëŠ” gpt_api.py ë¥¼ import
from gpt_api import generate_gpt_response, moderate_text, explain_why_blocked

app = FastAPI()

# CORS í—ˆìš© ì„¤ì • (React í”„ë¡ íŠ¸ì—”ë“œì—ì„œ 5173 í¬íŠ¸ë¡œ ìš”ì²­í•  ë•Œ í—ˆìš©ë˜ë„ë¡)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],         # ì‹¤ì œ ë°°í¬ ì‹œì—ëŠ” í—ˆìš©í•  ë„ë©”ì¸ë§Œ ëª…ì‹œì ìœ¼ë¡œ ì ì–´ì£¼ì„¸ìš”
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class Message(BaseModel):
    message: str


@app.post("/chat")
def chat_endpoint(msg: Message):
    user_message = msg.message

    # 1) ***ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•´ ëª¨ë”ë ˆì´ì…˜(ê²€ì‚¬) ìˆ˜í–‰***
    #    -> ìš•ì„¤, ì¦ì˜¤, í­ë ¥, ì„±ì  ìš”ì²­ ë“± ë¶€ì ì ˆí•œ ì‚¬ìš©ì ì…ë ¥ì´ flagged=Trueë¡œ ê°ì§€ë˜ëŠ”ì§€ í™•ì¸
    user_moderation = moderate_text(user_message)
    if user_moderation["flagged"]:
        # flaggedëœ ì¹´í…Œê³ ë¦¬ë“¤(ì˜ˆ: harassment, hate, violence ë“±)ë§Œ ê³¨ë¼ë‚´ê¸°
        flagged_list = [
            category for category, flagged in user_moderation["categories"].items() if flagged
        ]
        # â˜ ï¸ APE ê²½ê³  ë©”ì‹œì§€
        warning_text = "âš ï¸ ê°ì§€ëœ ìœ¤ë¦¬ì  ì´ìŠˆ: " + ", ".join(flagged_list)

        # ğŸ’¡ APE ì œì•ˆ ë©”ì‹œì§€
        suggestion_text = "ğŸ’¡ ë¶€ì ì ˆí•œ í‘œí˜„ ëŒ€ì‹  ì¢€ ë” ì¤‘ë¦½ì ì¸ ì–´íˆ¬ë¡œ ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”."

        # ğŸ§  ì°¨ë‹¨ ì´ìœ  ì„¤ëª…: explain_why_blocked í•¨ìˆ˜ë¥¼ ì¨ì„œ ê·¸ ì´ìœ ë¥¼ ìƒì„±
        #    (ì—¬ê¸°ì„œëŠ” ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì„¤ëª…í•˜ë„ë¡ ë„˜ê¹ë‹ˆë‹¤)
        explanation_text = "ğŸ§  " + explain_why_blocked(user_message)

        return {
            "reply": warning_text,
            "categories": user_moderation["categories"],
            "suggestion": suggestion_text,
            "explanation": explanation_text
        }

    # 2) ì‚¬ìš©ì ì…ë ¥ì´ ì•ˆì „í•˜ë‹¤ê³  íŒë‹¨ë˜ë©´, GPT-4ì—ê²Œ ì •ìƒ ë‹µë³€ ìš”ì²­
    gpt_reply = generate_gpt_response(user_message)

    # 3) (ì„ íƒ) GPTê°€ ìƒì„±í•œ ë‹µë³€ ìì²´ì— ëŒ€í•´ì„œë„ í•œë²ˆ ë” ëª¨ë”ë ˆì´ì…˜ì„ ëŒë ¤ë³´ê³  ì‹¶ë‹¤ë©´ ì—¬ê¸°ì— ì¶”ê°€
    #    ì˜ˆì‹œë¡œ, gpt_replyê°€ flagged=Trueì¸ ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ëŠ” ì½”ë“œë¥¼ ë„£ì–´ë‘ì—ˆìŠµë‹ˆë‹¤.
    gpt_moderation = moderate_text(gpt_reply)
    if gpt_moderation["flagged"]:
        flagged_list = [
            category for category, flagged in gpt_moderation["categories"].items() if flagged
        ]
        warning_text = "âš ï¸ GPT ì‘ë‹µì´ ì•ˆì „í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: " + ", ".join(flagged_list)
        suggestion_text = "ğŸ’¡ GPTê°€ ì¢€ ë” ì•ˆì „í•œ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ìœ ë„í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ë³´ì„¸ìš”."
        explanation_text = "ğŸ§  " + explain_why_blocked(gpt_reply)

        return {
            "reply": warning_text,
            "categories": gpt_moderation["categories"],
            "suggestion": suggestion_text,
            "explanation": explanation_text
        }

    # 4) ëê¹Œì§€ ë¬¸ì œ ì—†ë‹¤ë©´, ì •ìƒ GPT ì‘ë‹µì„ íšŒìƒ‰(bubble)ìœ¼ë¡œë§Œ ë°˜í™˜
    return {
        "reply": gpt_reply,
        "categories": {},
        "suggestion": None,
        "explanation": None
    }
